{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_solution_text(names, solution, solution_text):\n",
    "    \"\"\"\n",
    "    Verifies if the solution_text correctly describes the knight/knave status of each person.\n",
    "    \n",
    "    Args:\n",
    "        names: List of names\n",
    "        solution: List of booleans (True for knight, False for knave)\n",
    "        solution_text: String describing the solution\n",
    "    \n",
    "    Returns:\n",
    "        Boolean indicating if the solution_text is correct, and any discrepancies found\n",
    "    \"\"\"\n",
    "    # Make sure we have the same number of names and solutions\n",
    "    if len(names) != len(solution):\n",
    "        return False, \"Mismatch in lengths of names and solution arrays\"\n",
    "    \n",
    "    # Clean up the solution text and split by commas and 'and'\n",
    "    text = solution_text.split(\"RESULT:\")[-1].strip().replace('.', '')\n",
    "    # Handle 'and' at the end\n",
    "    text = text.replace(' and ', ', ')\n",
    "    \n",
    "    parts = text.split(', ')\n",
    "    \n",
    "    if len(parts) != len(names):\n",
    "        return False, f\"Solution text has {len(parts)} parts but there are {len(names)} people\"\n",
    "    \n",
    "    # Check each person\n",
    "    discrepancies = []\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        # Find which name this part refers to\n",
    "        name_idx = -1\n",
    "        for j, name in enumerate(names):\n",
    "            if name in part:\n",
    "                name_idx = j\n",
    "                break\n",
    "        \n",
    "        if name_idx == -1:\n",
    "            discrepancies.append(f\"Couldn't find any name in '{part}'\")\n",
    "            continue\n",
    "            \n",
    "        # Check if the knight/knave status is correct\n",
    "        is_knight = \"knight\" in part.lower()\n",
    "        is_knave = \"knave\" in part.lower()\n",
    "        \n",
    "        if is_knight and not solution[name_idx]:\n",
    "            discrepancies.append(f\"{names[name_idx]} is described as knight but should be knave\")\n",
    "        elif is_knave and solution[name_idx]:\n",
    "            discrepancies.append(f\"{names[name_idx]} is described as knave but should be knight\")\n",
    "        elif not is_knight and not is_knave:\n",
    "            discrepancies.append(f\"Couldn't determine if {names[name_idx]} is knight or knave in '{part}'\")\n",
    "    \n",
    "    return len(discrepancies) == 0, discrepancies\n",
    "\n",
    "# use the results to update the verified and discrepancies column of the data_[key]_[key]set\n",
    "def eval_dataset(data, field='solution_text', verified_col='verified', discrepancies_col='discrepancies'):\n",
    "    \"\"\"\n",
    "    Updates the dataset with verification results.\n",
    "    \n",
    "    Args:\n",
    "        data: The dataset to update\n",
    "    \"\"\"\n",
    "    verified = []\n",
    "    discrepancies = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        names = data['names'][i]\n",
    "        solution = data['solution'][i]\n",
    "        solution_text = data[field][i]\n",
    "        \n",
    "        is_verified, discrepancy_list = verify_solution_text(names, solution, solution_text)\n",
    "        \n",
    "        verified.append(is_verified)\n",
    "        discrepancies.append(\", \".join(discrepancy_list))\n",
    "    \n",
    "    data = data.add_column(verified_col, verified)\n",
    "    data = data.add_column(discrepancies_col, discrepancies)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen-2.5-0.5B-instruct-sft-lora-countdown-search-1k\n",
    "import sys\n",
    "sys.path.append('/cs/student/msc/ml/2024/ycheah/projects/sos/stream-of-search')\n",
    "from finetune.run_adapter_model import load_model, generate, generate_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 01:56:27,445 - INFO - PyTorch version 2.6.0 available.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import datasets\n",
    "data_ = datasets.load_dataset(\"K-and-K/knights-and-knaves\", name=\"test\")\n",
    "\n",
    "# {\n",
    "#     \"models_messages_field_pairs\":{\n",
    "#         \"2\": [\"chloeli/qwen-2.5-0.5B-instruct-sft-lora-countdown-search-react-correct-seq10k-5k\", \"messages_sos_react\", 128, \"MelinaLaimon/stream-of-search\"],\n",
    "#         \"3\": [\"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-react-correct-seq10k-5k\", \"messages_sos_react\", 128, \"MelinaLaimon/stream-of-search-ood\"],\n",
    "#         \"0\": [\"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-react-seq8k-5k\", \"messages_sos_react\", 128, \"MelinaLaimon/stream-of-search-ood\"],\n",
    "#         \"1\": [\"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-react-seq8k-5k\", \"messages_sos_react\", 128, \"MelinaLaimon/stream-of-search\"],\n",
    "#         \"8\": [\"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-seq8k-5k\", \"messages_sos\", 128, \"MelinaLaimon/stream-of-search\"],\n",
    "        \n",
    "#         \"4\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos-1k\", \"messages\", 128, \"yeok/stream-of-search-dataset_deepseek\"],\n",
    "#         \"5\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos_react-1k\", \"messages\", 128, \"yeok/stream-of-search-dataset_deepseek\"],\n",
    "#         \"6\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-optimal-1k\", \"messages\", 128, \"yeok/stream-of-search-dataset_deepseek\"],\n",
    "#         \"7\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-deepseek-1k\", \"messages\", 128, \"yeok/stream-of-search-dataset_deepseek\"],\n",
    "        \n",
    "#         \"9\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos-1k\", \"messages\", 128, \"MelinaLaimon/stream-of-search-ood\"],\n",
    "#         \"10\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos_react-1k\", \"messages\", 128, \"MelinaLaimon/stream-of-search-ood\"],\n",
    "#         \"11\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-optimal-1k\", \"messages\", 128, \"MelinaLaimon/stream-of-search-ood\"],\n",
    "#         \"12\": [\"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-deepseek-1k\", \"messages\", 128, \"MelinaLaimon/stream-of-search-ood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 01:56:33,431 - INFO - Using base model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "2025-04-04 01:56:33,432 - INFO - Loading base model without quantization...\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "2025-04-04 01:56:38,773 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2025-04-04 02:00:35,757 - INFO - Applying LoRA adapters...\n",
      "4it [01:59, 29.91s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ppl score: 2.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:18, 19.54s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ppl score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:20, 20.13s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ppl score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 02:05:30,842 - INFO - Using base model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "2025-04-04 02:05:30,844 - INFO - Loading base model without quantization...\n",
      "2025-04-04 02:05:31,007 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2025-04-04 02:05:31,519 - INFO - Applying LoRA adapters...\n",
      "4it [01:16, 19.09s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ppl score: 2.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:18, 19.58s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ppl score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:20, 20.10s/it]                       \n",
      "2025-04-04 02:09:43,113 - INFO - Using base model: Qwen/Qwen2.5-1.5B-Instruct\n",
      "2025-04-04 02:09:43,114 - INFO - Loading base model without quantization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ppl score: 1.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 02:09:43,263 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2025-04-04 02:09:43,761 - INFO - Applying LoRA adapters...\n",
      "4it [01:16, 19.13s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ppl score: 5.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:22<00:45, 22.64s/it]"
     ]
    }
   ],
   "source": [
    "context_len = 512\n",
    "temperature = 0.7\n",
    "\n",
    "keys = [\"2ppl\", \"3ppl\", \"4ppl\"]\n",
    "results = {}\n",
    "results['trajectories'] = {}\n",
    "results['scores'] = {}\n",
    "\n",
    "for adapter in [\n",
    "    \"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos-1k\",\n",
    "    \"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-sos_react-1k\",\n",
    "    \"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-optimal-1k\",\n",
    "    \"yeok/qwen-2.5-1.5B-instruct-sft-lora-countdown-deepseek-1k\",\n",
    "    \"chloeli/qwen-2.5-0.5B-instruct-sft-lora-countdown-search-react-correct-seq10k-5k\", \n",
    "    \"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-react-seq8k-5k\",\n",
    "    \"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-seq8k-5k\",\n",
    "    ]:\n",
    "# adapter=\"chloeli/qwen-2.5-1.5B-instruct-sft-lora-countdown-search-react-1k\"\n",
    "    batch_size=32\n",
    "    model, tokenizer = load_model(adapter)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    def message_template(example_question):\n",
    "        return [{ \"content\": f\"{example_question}.\\nConclude with the final result in EXACTLY this format:\\n```\\nSOLUTION: YES/NO\\ \\nRESULT: final_value\\n```\\nThe final_value should be statements separated by commas. For example, 'Michael is a knight, Zoey is a knight, and Ethan is a knight.'\", \"role\": \"user\" }]\n",
    "\n",
    "    for key in keys:\n",
    "        output_texts_concat = []\n",
    "\n",
    "        data = data_[key]\n",
    "        data = data.map(lambda x: {\n",
    "            \"test_prompt\": message_template(x['quiz']) \n",
    "        })\n",
    "        \n",
    "        # Generate completions for this batch\n",
    "        for i, data_batch in tqdm(enumerate(data.iter(batch_size=batch_size)), total=len(data)//batch_size):   \n",
    "            chat_inputs = tokenizer.apply_chat_template(data_batch[\"test_prompt\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=context_len, return_length=True, tokenize=False)\n",
    "            outputs = generate_batch(model, tokenizer, chat_inputs, max_new_tokens=context_len, temperature=temperature)\n",
    "            output_texts_concat.extend(outputs)\n",
    "\n",
    "        # Add completions column to dataset\n",
    "        column_name = f\"completions_{key}\"\n",
    "        data = data.add_column(column_name, output_texts_concat)\n",
    "        \n",
    "        # Evaluate completions\n",
    "        verified_column = f\"verified_{key}\"\n",
    "        discrepancies_column = f\"discrepancies_{key}\"\n",
    "        data = eval_dataset(data, column_name, verified_column, discrepancies_column)\n",
    "        \n",
    "        # Calculate score\n",
    "        score = data[verified_column].count(True) / len(data) * 100\n",
    "        print(f\"{key} score: {score:.2f}%\")\n",
    "        \n",
    "        # Store score and trajectories\n",
    "        results['scores'][key] = score\n",
    "        results['trajectories'][key] = []\n",
    "        \n",
    "        # Create trajectory data using the correct column names for each key\n",
    "        for i in range(len(data)):\n",
    "            results['trajectories'][key].append({\n",
    "                'completions': data[column_name][i],\n",
    "                'verified': data[verified_column][i],\n",
    "                'discrepancies': data[discrepancies_column][i]\n",
    "            })\n",
    "\n",
    "    import json, os\n",
    "    savepath = f\"./results/ood/{adapter}/knk.json\"\n",
    "    os.makedirs(os.path.dirname(savepath), exist_ok=True)\n",
    "    with open(savepath, 'w') as f:\n",
    "        json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob, re\n",
    "def visualize_example_count_performance():\n",
    "    \"\"\"\n",
    "    Visualize model performance by number of examples (3num vs 5num),\n",
    "    clustered by example count with model types within each cluster\n",
    "    \"\"\"\n",
    "    # Store data by example count and model type\n",
    "    data_by_example_count = {}\n",
    "    \n",
    "    # Find all relevant JSON files in qwen folders\n",
    "    for folder in glob.glob(\"./results/qwen*\".lower()):\n",
    "        folder_name = os.path.basename(folder)\n",
    "        \n",
    "        # Extract model size\n",
    "        model_size = folder_name.split(\"-instruct\")[0].split(\"2.5-\")[-1]\n",
    "        \n",
    "        # Extract approach type (search-seq8k vs search-react-seq8k)\n",
    "        approach_match = re.search(r'countdown-(search-[^_-]+)', folder_name)\n",
    "        if approach_match:\n",
    "            approach_type = approach_match.group(1)\n",
    "        else:\n",
    "            # Fallback to a more general pattern\n",
    "            approach_match = re.search(r'countdown-([^_]+)', folder_name)\n",
    "            approach_type = approach_match.group(1) if approach_match else \"unknown\"\n",
    "            \n",
    "        model_key = f\"{model_size}-{approach_type}\"\n",
    "        \n",
    "        for file in glob.glob(f\"{folder}/countdown_*.json\"):\n",
    "            with open(file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            hyperparams = data[0]['hyperparams']\n",
    "            mean_success_rate = data[1]['mean']\n",
    "            sample_size = hyperparams['num']\n",
    "            \n",
    "            # Extract example count from filename\n",
    "            filename = os.path.basename(file)\n",
    "            example_count_match = re.search(r'countdown_(\\d+)num_(\\d+)', filename)\n",
    "            \n",
    "            if example_count_match:\n",
    "                example_count = int(example_count_match.group(1))\n",
    "                dataset_size = int(example_count_match.group(2))\n",
    "                \n",
    "                # Store data grouped by example count first\n",
    "                example_key = f\"{example_count}num\"\n",
    "                if example_key not in data_by_example_count:\n",
    "                    data_by_example_count[example_key] = {}\n",
    "                \n",
    "                if model_key not in data_by_example_count[example_key]:\n",
    "                    data_by_example_count[example_key][model_key] = []\n",
    "                \n",
    "                data_by_example_count[example_key][model_key].append({\n",
    "                    'success_rate': mean_success_rate,\n",
    "                    'sample_size': sample_size,\n",
    "                    'dataset_size': dataset_size,\n",
    "                    'file': filename\n",
    "                })\n",
    "    \n",
    "    # Create visualization if we have data\n",
    "    if not data_by_example_count:\n",
    "        print(\"No example count data found.\")\n",
    "        return\n",
    "    \n",
    "    # Sort example counts and model types\n",
    "    example_counts = sorted(data_by_example_count.keys())\n",
    "    all_model_types = sorted(set(model for example_data in data_by_example_count.values() \n",
    "                                for model in example_data.keys()))\n",
    "    \n",
    "    # Create figure for bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Set up the bar positions\n",
    "    x = np.arange(len(example_counts))\n",
    "    bar_width = 0.8 / len(all_model_types)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(all_model_types)))\n",
    "    \n",
    "    # Plot bars grouped by example count, with model types within each cluster\n",
    "    for i, model_type in enumerate(all_model_types):\n",
    "        avg_rates = []\n",
    "        sample_sizes = []\n",
    "        \n",
    "        for count in example_counts:\n",
    "            if count in data_by_example_count and model_type in data_by_example_count[count]:\n",
    "                runs = data_by_example_count[count][model_type]\n",
    "                avg_rate = np.mean([run['success_rate'] for run in runs])\n",
    "                avg_rates.append(avg_rate)\n",
    "                max_sample = max([run['sample_size'] for run in runs])\n",
    "                sample_sizes.append(max_sample)\n",
    "            else:\n",
    "                avg_rates.append(0)\n",
    "                sample_sizes.append(0)\n",
    "        \n",
    "        # Position bars within each cluster\n",
    "        offset = i - (len(all_model_types) - 1) / 2\n",
    "        x_pos = x + offset * bar_width\n",
    "        \n",
    "        # Plot the bars\n",
    "        bars = plt.bar(x_pos, avg_rates, width=bar_width, label=model_type, color=colors[i])\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, value, sample in zip(bars, avg_rates, sample_sizes):\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, height + 0.01,\n",
    "                        f\"{value:.2f}\\nn={sample}\", ha='center', va='bottom', \n",
    "                        fontsize=8)\n",
    "    \n",
    "    # Configure the plot\n",
    "    plt.xlabel('Number of Examples in Input', fontsize=12)\n",
    "    plt.ylabel('Success Rate', fontsize=12)\n",
    "    plt.title('Model Performance by Number of Examples', fontsize=14)\n",
    "    plt.xticks(x, example_counts)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(title='Model Types', loc='upper center', bbox_to_anchor=(0.5, -0.1), \n",
    "              ncol=min(3, len(all_model_types)))\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(\"./results/example_count_performance.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "visualize_example_count_performance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sos1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
